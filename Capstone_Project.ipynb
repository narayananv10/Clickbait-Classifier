{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subjective-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "mwe = MWETokenizer()\n",
    "lemma = WordNetLemmatizer()\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.python.keras.layers import  Dropout, Dense\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lyric-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "clickdata=gzip.open(\"clickbait_data.gz\", \"rb\")\n",
    "nonclickdata=gzip.open(\"non_clickbait_data.gz\", \"rb\")\n",
    "click_df=pd.read_csv(clickdata, delimiter=\"\\n\", header=None)\n",
    "nonclick_df=pd.read_csv(nonclickdata, delimiter=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "single-basics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15999, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should I Get Bings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which TV Female Friend Group Do You Belong In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The New \"Star Wars: The Force Awakens\" Trailer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Vine Of New York On \"Celebrity Big Brothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Couple Did A Stunning Photo Shoot With Their...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                 Should I Get Bings\n",
       "1      Which TV Female Friend Group Do You Belong In\n",
       "2  The New \"Star Wars: The Force Awakens\" Trailer...\n",
       "3  This Vine Of New York On \"Celebrity Big Brothe...\n",
       "4  A Couple Did A Stunning Photo Shoot With Their..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(click_df.shape)\n",
    "click_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manual-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16001, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bill Changing Credit Card Rules Is Sent to Oba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Hollywood, the Easy-Money Generation Toughe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1700 runners still unaccounted for in UK's Lak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yankees Pitchers Trade Fielding Drills for Put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Large earthquake rattles Indonesia; Seventh in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Bill Changing Credit Card Rules Is Sent to Oba...\n",
       "1  In Hollywood, the Easy-Money Generation Toughe...\n",
       "2  1700 runners still unaccounted for in UK's Lak...\n",
       "3  Yankees Pitchers Trade Fielding Drills for Put...\n",
       "4  Large earthquake rattles Indonesia; Seventh in..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nonclick_df.shape)\n",
    "nonclick_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "animated-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_df[\"Clickbait\"] = 1\n",
    "nonclick_df[\"Clickbait\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "owned-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 2)\n"
     ]
    }
   ],
   "source": [
    "df = click_df.append(nonclick_df, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "upper-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['news','Clickbait']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charitable-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "  token = text.split()\n",
    "  return ' '.join([w for w in token if not w in english_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "swiss-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "  return mwe.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "public-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "  return ''.join([lemma.lemmatize(word,'v') for word in mwe.tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "circular-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortwords(text):\n",
    "  text = ' '.join([w for w in text.split() if len(w)>2])\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affected-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "  text = [i for i in text if i.isalpha() or i.isspace()]\n",
    "  return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "average-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "  s = s.lower()\n",
    "  text = remove_stopwords(s)\n",
    "  text = shortwords(text)\n",
    "  text = remove_punctuation(text)\n",
    "  text = tokenize(text)\n",
    "  text = lemmatize(text)\n",
    "  \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "marked-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.news = df.news.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proprietary-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>Clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get bings</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female friend group belong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new star wars force awakens trailer give chills</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vine new york celebrity big brother fucking pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>couple stunning photo shoot baby learning inop...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  Clickbait\n",
       "0                                          get bings          1\n",
       "1                         female friend group belong          1\n",
       "2    new star wars force awakens trailer give chills          1\n",
       "3  vine new york celebrity big brother fucking pe...          1\n",
       "4  couple stunning photo shoot baby learning inop...          1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "subsequent-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = df.news\n",
    "y = df.Clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "western-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "curious-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fuzzy-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = X.todense().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "successful-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(dense, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ruled-vision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaevpc</th>\n",
       "      <th>aap</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarons</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandons</th>\n",
       "      <th>...</th>\n",
       "      <th>złoty</th>\n",
       "      <th>ºf</th>\n",
       "      <th>ángel</th>\n",
       "      <th>íngrid</th>\n",
       "      <th>íslands</th>\n",
       "      <th>îledefrance</th>\n",
       "      <th>ürümqi</th>\n",
       "      <th>śrī</th>\n",
       "      <th>šibenik</th>\n",
       "      <th>Clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  aaevpc  aap  aaron  aarons   ab  abandon  abandoned  abandoning  \\\n",
       "0  0.0     0.0  0.0    0.0     0.0  0.0      0.0        0.0         0.0   \n",
       "1  0.0     0.0  0.0    0.0     0.0  0.0      0.0        0.0         0.0   \n",
       "2  0.0     0.0  0.0    0.0     0.0  0.0      0.0        0.0         0.0   \n",
       "3  0.0     0.0  0.0    0.0     0.0  0.0      0.0        0.0         0.0   \n",
       "4  0.0     0.0  0.0    0.0     0.0  0.0      0.0        0.0         0.0   \n",
       "\n",
       "   abandons  ...  złoty   ºf  ángel  íngrid  íslands  îledefrance  ürümqi  \\\n",
       "0       0.0  ...    0.0  0.0    0.0     0.0      0.0          0.0     0.0   \n",
       "1       0.0  ...    0.0  0.0    0.0     0.0      0.0          0.0     0.0   \n",
       "2       0.0  ...    0.0  0.0    0.0     0.0      0.0          0.0     0.0   \n",
       "3       0.0  ...    0.0  0.0    0.0     0.0      0.0          0.0     0.0   \n",
       "4       0.0  ...    0.0  0.0    0.0     0.0      0.0          0.0     0.0   \n",
       "\n",
       "   śrī  šibenik  Clickbait  \n",
       "0  0.0      0.0          1  \n",
       "1  0.0      0.0          1  \n",
       "2  0.0      0.0          1  \n",
       "3  0.0      0.0          1  \n",
       "4  0.0      0.0          1  \n",
       "\n",
       "[5 rows x 23841 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([new_df,y],axis=1,sort=False)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deluxe-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = final_df.drop(columns=\"Clickbait\")\n",
    "y1 = final_df[\"Clickbait\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "generous-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_df,dense,X,y, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "reserved-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1train,X1test,y1train,y1test = tts(X1,y1,test_size = 0.3,stratify=y1, random_state=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aquatic-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1train = X1train.to_numpy()\n",
    "X1test = X1test.to_numpy()\n",
    "y1train = y1train.to_numpy()\n",
    "y1test = y1test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "consolidated-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22400, 23840)\n"
     ]
    }
   ],
   "source": [
    "print(X1train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "listed-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(25,input_shape=(X1train.shape[1],),activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "atmospheric-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(lr=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "integral-powder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "131/131 [==============================] - 6s 46ms/step - loss: 0.6872 - accuracy: 0.5548 - val_loss: 0.6769 - val_accuracy: 0.8914\n",
      "Epoch 2/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.6028 - accuracy: 0.7409 - val_loss: 0.4412 - val_accuracy: 0.9393\n",
      "Epoch 3/10\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.4650 - accuracy: 0.8521 - val_loss: 0.3077 - val_accuracy: 0.9418\n",
      "Epoch 4/10\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.3678 - accuracy: 0.8946 - val_loss: 0.2808 - val_accuracy: 0.9330\n",
      "Epoch 5/10\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.3178 - accuracy: 0.9145 - val_loss: 0.2720 - val_accuracy: 0.9397\n",
      "Epoch 6/10\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2845 - accuracy: 0.9267 - val_loss: 0.2609 - val_accuracy: 0.9383\n",
      "Epoch 7/10\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2552 - accuracy: 0.9385 - val_loss: 0.2679 - val_accuracy: 0.9357\n",
      "Epoch 8/10\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2324 - accuracy: 0.9425 - val_loss: 0.2824 - val_accuracy: 0.9372\n",
      "Epoch 9/10\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2182 - accuracy: 0.9471 - val_loss: 0.2835 - val_accuracy: 0.9323\n",
      "Epoch 10/10\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.2034 - accuracy: 0.9520 - val_loss: 0.2944 - val_accuracy: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd2235a9bb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X1train, y1train,\n",
    "          validation_split=0.3,\n",
    "          epochs = 10,\n",
    "          batch_size = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "complete-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2701 - accuracy: 0.9379\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X1test, y1test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caring-czech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-33ad9057b8a7>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4359,  441],\n",
       "       [ 155, 4645]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict_classes(X1test)\n",
    "matr=confusion_matrix(y1test, pred)\n",
    "matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "capable-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25)                596025    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 596,637\n",
      "Trainable params: 596,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "colored-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fewer-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('best_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-homework",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
